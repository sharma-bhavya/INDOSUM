# INDOSUM
I did this project as part of my NLP course in 5th Semester. It was a Shared Task named ILSUM 2023 organized by Forum for Information Retrieval Information (FIRE) in association with ACM. It was a task where we were provided with datasets containing news and summary pairs in English, Hindi, Bengali, Gujrati. Our task was to create a NLP model that could summarize the given text in the following languages in a fixed length summary of 75 words. Notably, I achieved Rank 1 all over India and got a BERT Score of 87.57. For English i used transformer model from Google named T5 and fine tuned it completely from scratch using the enire dataset, followed by various extractive summarization techniques like Text frequency, TFIDF, K-Means and BERT. As my novelty, i introduced a unique concept of Extractive + Abstractive summarization where rather than providing the entire article to the model (T5), i only provided it with the extractive summary from BERT which was around 150 words. This improved our ROUGE scores drastically to 49.8. For Hindi, i used IndicBART and MT5 and got a highest ROUGE score of 73. Due to confidential reasons, i cannot provide the entire code here, so im just providing some of the code, for the entire source code you can mail me at shrmabhav10@gmail.com . Our paper got selected for publication in CEUR proceedings 2023.
